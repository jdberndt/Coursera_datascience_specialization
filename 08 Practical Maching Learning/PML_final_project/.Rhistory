type = "lower",
tl.cex = 0.5
) #create clustered heatmap of the correlation among variables
corrplot(
which(abs(corvars) > 0.8, arr.ind = T),
method = "square",
type = "lower",
tl.cex = 0.5
) #create clustered heatmap correlations among features
corrplot(
corvars,
method = "square",
type = "lower",
tl.cex = 0.5
) #create clustered heatmap correlations among features
corvars <- cor(training[, -53]) #create correlation matrix
corvars[lower.tri(corvars, diag = T)] <- 0 #fill lower tri and diag with 0
indices <- which(abs(corvars) > 0.8, arr.ind = T) #determine indices of highly correlated variables
indices
corvars <- cor(training[, -53]) #create correlation matrix
indices <- which(abs(corvars) > 0.8, arr.ind = T) #determine indices of highly correlated variables
indices
names(indices)
rownames(indices)
corvarssub <- corvars[,rownames(indices)]
corvarssub
corrplot(
corvarssub,
method = "square",
type = "lower",
tl.cex = 0.5
) #create clustered heatmap correlations among features
ncol(corvarssub)
corvarssub <- corvars[,unique(rownames(indices))]
ncol(corvarssub)
unique(rownames(indices))
nrow(indices)
corvars <- cor(training[, -53]) #create correlation matrix
diag(corvars) <- 0
indices <- which(abs(corvars) > 0.8, arr.ind = T) #determine indices of highly correlated variables
nrow(indices)
unique(rownames(indices))
corvarssub <- corvars[,unique(rownames(indices))]
ncol(corvarssub)
corrplot(
corvarssub,
method = "square",
type = "lower",
tl.cex = 0.5
) #create clustered heatmap correlations among features
nrow(corvarssub)
corvarssub <- corvars[unique(rownames(indices)),unique(rownames(indices))]
corrplot(
corvarssub,
method = "square",
type = "lower",
tl.cex = 0.5
) #create clustered heatmap correlations among features
indices
corrplot(
corvarssub,
method = "square",
type = "lower",
tl.cex = 0.5,
diag = F
) #create clustered heatmap correlations among features
corrplot(
corvarssub,
method = "square",
type = "lower",
tl.cex = 0.5,
diag = T
) #create clustered heatmap correlations among features
diag(corvarssub) <- 1
corrplot(
corvarssub,
method = "square",
type = "lower",
tl.cex = 0.5,
diag = T
) #create clustered heatmap correlations among features
corrplot(
corvars,
method = "square",
type = "upper",
tl.cex = 0.5,
diag = T
) #create clustered heatmap correlations among features
corvars <- cor(training[, -53]) #create correlation matrix
diag(corvars) <- 0
indices <- which(abs(corvars) > 0.8, arr.ind = T) #determine indices of highly correlated variables
corvars <- corvars[unique(rownames(indices)), unique(rownames(indices))]
diag(corvars) <- 1
corrplot(
corvars,
method = "square",
type = "upper",
tl.cex = 0.5,
diag = T
) #create clustered heatmap correlations among features
corrplot(
corvars,
method = "square",
type = "upper",
tl.cex = 0.5,
hclust.method = "complete"
) #create clustered heatmap correlations among features
corrplot(
corvars,
method = "square",
type = "upper",
tl.cex = 0.5,
) #create clustered heatmap correlations among features
corvars <- cor(training[, -53]) #create correlation matrix
diag(corvars) <- 0
indices <- which(abs(corvars) > 0.9, arr.ind = T) #determine indices of highly correlated variables
corvars <- corvars[unique(rownames(indices)), unique(rownames(indices))]
diag(corvars) <- 1
corrplot(
corvars,
method = "square",
type = "upper",
tl.cex = 0.5
) #create a heatmap of highly correlated features
corvars <- cor(training[, -53]) #create correlation matrix
diag(corvars) <- 0
indices <- which(abs(corvars) > 0.7, arr.ind = T) #determine indices of highly correlated variables
corvars <- corvars[unique(rownames(indices)), unique(rownames(indices))]
diag(corvars) <- 1
corrplot(
corvars,
method = "square",
type = "upper",
tl.cex = 0.5
) #create a heatmap of highly correlated features
?corrplot
corrplot(
corvars,
method = "square",
type = "upper",
order = "hclust"
tl.cex = 0.5
corrplot(
corvars,
method = "square",
type = "upper",
order = "hclust",
tl.cex = 0.5
) #create a heatmap of highly correlated features
corrplot(
corvars,
method = "square",
type = "upper",
order = "AOE",
tl.cex = 0.5
) #create a heatmap of highly correlated features
corrplot(
corvars,
method = "square",
type = "upper",
order = "FPC",
tl.cex = 0.5
) #create a heatmap of highly correlated features
corrplot(
corvars,
method = "square",
type = "upper",
order = "AOE",
tl.cex = 0.5
) #create a heatmap of highly correlated features
PC
corrplot(
corvars,
method = "square",
type = "upper",
order = "FPC",
tl.cex = 0.5
) #create a heatmap of highly correlated features
corrplot(
corvars,
method = "square",
type = "upper",
order = "FPC",
diag = F
tl.cex = 0.5
corrplot(
corvars,
method = "square",
type = "upper",
order = "FPC",
diag = F,
tl.cex = 0.5
) #create a heatmap of highly correlated features
corvars <- cor(training[, -53]) #create correlation matrix
diag(corvars) <- 0
indices <- which(abs(corvars) > 0.8, arr.ind = T) #determine indices of highly correlated variables
corvars <- corvars[unique(rownames(indices)), unique(rownames(indices))]
diag(corvars) <- 1
corrplot(
corvars,
method = "square",
type = "upper",
order = "FPC",
diag = F,
tl.cex = 0.5
) #create a heatmap of highly correlated features
corrplot(
corvars,
method = "square",
type = "upper",
order = "FPC",
diag = F,
tl.cex = 0.7
) #create a heatmap of highly correlated features
corvars <- cor(training[, -53]) #create correlation matrix
diag(corvars) <- 0
indices <- which(abs(corvars) > 0.8, arr.ind = T) #determine names of highly correlated variables
corvars <- corvars[unique(rownames(indices)), unique(rownames(indices))] #subset matrix
corrplot(
corvars,
method = "square",
type = "upper",
order = "FPC",
diag = T,
tl.cex = 0.7
) #create a heatmap of highly correlated features
diag(corvars) <- 1
corrplot(
corvars,
method = "square",
type = "upper",
order = "FPC",
diag = T,
tl.cex = 0.7
) #create a heatmap of highly correlated features
set.seed(2358)
fitControl <- trainControl(method = "cv", number = 5, allowParallel = TRUE) #define parameters for cross validation
fitlda <- train(classe~., method="lda", preProcess = "pca" , data=training, trControl = fitControl) #train lda with PCA dim reduction
fitglm <- train(classe~., method="glm", preProcess = "pca" , data=training, trControl = fitControl) #train glm with PCA dim reduction
fitglm <- train(classe~., method="lm", preProcess = "pca" , data=training, trControl = fitControl) #train glm with PCA dim reduction
set.seed(2358)
fitada <- train(classe~., method="adaboost", preProcess = "pca" , data=training, trControl = fitControl) #train boost with PCA dim reduction
fitada <- train(classe~., method="gam", preProcess = "pca" , data=training, trControl = fitControl) #train boost with PCA dim reduction
fitControl <- trainControl(method = "cv", number = 5, allowParallel = TRUE) #define parameters for cross validation
cluster <- makeCluster(detectCores() - 1); registerDoParallel(cluster) #initiate cluster for parallel processing
fitControl <- trainControl(method = "cv", number = 5, allowParallel = TRUE) #define parameters for cross validation
set.seed(2358)
fitlda <- train(classe~., method="lda", preProcess = "pca" , data=training, trControl = fitControl) #train lda with PCA dim reduction
fitglm <- train(classe~., method="glm", preProcess = "pca" , data=training, trControl = fitControl) #train glm with PCA dim reduction
fittree <- train(classe~., method="rpart", data=training, trControl = fitControl) #train tree classification
fitgbm <- train(classe~., method="gbm", data=training, trControl = fitControl) #train gbm classification
fitlasso <- train(classe~., method="lasso", preProcess = "pca" , data=training, trControl = fitControl) #train lasso with PCA dim reduction
fitridge <- train(classe~., method="ridge", preProcess = "pca" , data=training, trControl = fitControl) #train lasso with PCA dim reduction
fitsvm <- train(classe~., method="svm", data=training, trControl = fitControl) #train svm
fitrf <- train(classe~., method="rf", data=training, trControl = fitControl) #train random forest classification
fitlda
fittree
fitgbm
fitrf
??Svm
library(e1071)
?svm
fitsvm <- svm(classe~., data=training, type = C, cross = 5)
fitsvm <- svm(classe~., data=training, type = "C", cross = 5)
fitsvm
summary(fitsvm)
fitsvm$coefs
summary(fitsvm)$accuracy
summary(fitsvm)
stopCluster(cluster); registerDoSEQ() #return to single thread
summary(fitrf)
fitrf
fitrf
fitrf$finalModel
fitgbm$finalModel
fitlda$finalModel
fittree$finalModel
fittree
fitlda
fitlda$results
fitlda$results[2]
fittree$results[2]
fittree
max(fitlda$results[2])
fitgbm$results
fitgbm
max(fitlda$results[2])
max(fittree$results[2])
max(fitgbm$results[2])
fitgbm$results
max(fitgbm$results[5])
ftisvm$results
fitsvm$results
fitsvm
summary(fitsvm)
unlist(summary(fitsvm))
summary(fitsvm)
summary(fitsvm)[3]
summary(fitsvm)[5]
summary(fitsvm)[8]
summary(fitsvm)[11]
str(fitsvm)
fit.svm$tot.accuracy
fitsvm$tot.accuracy
fitsvm$tot.accuracy/100
fitrf
fitrf$results
data.frame(model = c("lda", "tree","gbm","svm","rf"), accuracy = c(1,2,3,4,5))
data.frame(model = c("lda", "tree","gbm","svm","rf"),
accuracy = c(max(fitlda$results[2]),
max(fittree$results[2]),
max(fitgbm$results[5]),
fitsvm$tot.accuracy/100,
max(fitrf$results[2])))
confusionMatrix(fitlda, validation)
confusionMatrix(fitlda, validation, norm = "average")
confusionMatrix(predict(fitlda, validation), validation$classe)
confusionMatrix(predict(fitlda, validation), validation$classe)$overall
confusionMatrix(predict(fitlda, validation), validation$classe)$overall[1]
oosafunc <- function(x){confusionMatrix(predict(x, validation), validation$classe)$overall[1]}
oosa <- sapply(c(fitlda, fittree, fitgbm, fitsvm, fitrf), oosafunc)
oosafunc(fitlda)
oosafunc(fitgbm)
oosa <- sapply(list(c(fitlda, fittree, fitgbm, fitsvm, fitrf)), oosafunc)
fits <- list(c(fitlda, fittree, fitgbm, fitsvm, fitrf))
fits
class(fits)
class(fits[1])
class(fitlda)
class(fitsvm)
fitrf
fitrf$finalModel
fitrf$finalModel[3]
fitrf$finalModel[4]
fitrf$finalModel[6
]
str(fitrf$finalModel)
fitrf$finalModel$err.rate
fitrf$finalModel$confusion
fitrf$finalModel$oob.times
fitrf$finalModel
fitrf$finalModel$param
str(fitrf$finalModel)
fitrf$finalModel$param
fitrf$finalModel
fitrf$finalModel[-"confusion"]
fitrf$finalModel[-confusion]
fitrf$finalModel[,-confusion]
confusionMatrix(predict(fitrf, validation), validation$classe)
confusionMatrix(predict(fitrf, validation), validation$classe)$overall
View(testing)
ncol(testing)
predict(fitrf, testing)
predict(fitrf, testing[,-53])
cbind(testing$problemID, classe = predict(fitrf, testing))
cbind(testing$problemID, classe = predict(fitrf, testing)[1])
classe <- predict(fitrf, testing)
classe
class(classe)
class(testing$problem_id)
data.frame(testing$problem_id, classe = predict(fitrf, testing))
testing <- read.csv("pml-testing.csv", na.strings = c("","NA", "#DIV/0!"))
testing <- read.csv("pml-testing.csv", na.strings = c("","NA", "#DIV/0!"))
data.frame(testing$problem_id, classe = predict(fitrf, testing))
data.frame(testing$problem_id, classe.prediction = predict(fitrf, testing))
fitrf2
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(caret)
library(corrplot)
library(parallel)
library(doParallel)
library(e1071)
if(!file.exists("pml-training.csv")){download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "pml-training.csv", method ="curl")}
if(!file.exists("pml-testing.csv")){download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "pml-training.csv", method ="curl")}
training <- read.csv("pml-training.csv", na.strings = c("","NA", "#DIV/0!"))
testing <- read.csv("pml-testing.csv", na.strings = c("","NA", "#DIV/0!"))
nacount <- sapply(training, function(x){sum(is.na(x))}) #counts NAs in each column
omitcols <- names(nacount[nacount > nrow(training)*.5]) #identifies columns with more than half NAs
training <- training%>%select(-omitcols) #subsets data to omit columns with mostly NAs
training <- training%>%select(-c(1:7)) #subsets data to omit columns with non-predictive variables, e.g. timestamp
nearZeroVar(training) #check for additional variables with little variation, there were none
set.seed(666) #spawn the devil's seed
in_train <- createDataPartition(training$classe, p = 0.75, list = FALSE)
validation <- training[-in_train,]
training <- training[in_train,]
corvars <- cor(training[, -53]) #create correlation matrix
diag(corvars) <- 0
indices <- which(abs(corvars) > 0.8, arr.ind = T) #determine names of highly correlated variables
corvars <- corvars[unique(rownames(indices)), unique(rownames(indices))] #subset matrix
diag(corvars) <- 1
corrplot(
corvars,
method = "square",
type = "upper",
order = "FPC",
tl.cex = 0.7
) #create a heatmap of highly correlated features
cluster <- makeCluster(detectCores() - 1); registerDoParallel(cluster) #initiate cluster for parallel processing
fitControl <- trainControl(method = "cv", number = 5, allowParallel = TRUE) #define parameters for cross validation
set.seed(2358)
fitlda <- train(classe~., method="lda", preProcess = "pca" , data=training, trControl = fitControl) #train lda with PCA dim reduction
fittree <- train(classe~., method="rpart", data=training, trControl = fitControl) #train tree classification
fitgbm <- train(classe~., method="gbm", data=training, trControl = fitControl) #train gbm classification
fitsvm <- svm(classe~., data=training, type = "C", cross = 5) #train svm classification
fitrf <- train(classe~., method="rf", data=training, trControl = fitControl) #train random forest classification
data.frame(model_type = c("lda", "tree","gbm","svm","rf"),
in_sample_accuracy = c(max(fitlda$results[2]),
max(fittree$results[2]),
max(fitgbm$results[5]),
fitsvm$tot.accuracy/100,
max(fitrf$results[2]))
) #compares in sample accuracies
fitrf$finalModel #shows OOB error
confusionMatrix(predict(fitrf, validation), validation$classe)$overall #shows OOSA and CI
vars <- varImp(fitrf)$importance #determine feature importance
vars <- vars%>%mutate(names=rownames(vars))%>%arrange(desc(Overall))%>%filter(Overall>10) #select top 20 or so features
corrplot(
cor(training[, vars$names]),
method = "square",
type = "upper",
order = "FPC",
tl.cex = 0.7
) #plots heatmap of feature cross correlation
newformula <- paste0("classe~", vars$names[1])
for (i in 2:length(vars$names)){newformula <- paste(newformula, vars$names[i], sep="+")} #define a new formula
fitrf2 <- train(as.formula(newformula), method="rf", data=training, trControl = fitControl) #refit the rf model
fitrf2$finalmodel #shows OOB error
confusionMatrix(predict(fitrf2, validation), validation$classe)$overall #shows OOSA and CI
data.frame(testing$problem_id, classe.prediction.fitrf = predict(fitrf, testing), classe.prediction.fitrf2 = predict(fitrf2, testing))
stopCluster(cluster); registerDoSEQ() #return to single thread
system.time(fitrf)
fitrf2$finalModel
?vif
??vif
fittime <- system.time(print("Hello"))
fittime
paste0("fittime", fittime)
print("The fit time was:"); fittime
cat("The fit time was:"); fittime
cat("The fit time was:") fittime
cat("The fit time was:")
fittime
fittime[3]
fittime[[3]]
data.frame(first_fit = fittime, second_fit = fittime)
data.frame(first_fit = as.list(fittime), second_fit = as.list(fittime))
data.frame(rbind(first_fit = as.list(fittime), second_fit = as.list(fittime)))
data.frame(rbind(first_fit = fittime, second_fit = fittime))
data.frame(rbind(first_fit = fittime[3], second_fit = fittime[3]))
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(caret)
library(corrplot)
library(parallel)
library(doParallel)
library(e1071)
if(!file.exists("pml-training.csv")){download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "pml-training.csv", method ="curl")}
if(!file.exists("pml-testing.csv")){download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "pml-training.csv", method ="curl")}
training <- read.csv("pml-training.csv", na.strings = c("","NA", "#DIV/0!"))
testing <- read.csv("pml-testing.csv", na.strings = c("","NA", "#DIV/0!"))
nacount <- sapply(training, function(x){sum(is.na(x))}) #counts NAs in each column
omitcols <- names(nacount[nacount > nrow(training)*.5]) #identifies columns with more than half NAs
training <- training%>%select(-omitcols) #subsets data to omit columns with mostly NAs
training <- training%>%select(-c(1:7)) #subsets data to omit columns with non-predictive variables, e.g. timestamp
nearZeroVar(training) #check for variables with little variation
set.seed(666) #spawn the devil's seed
in_train <- createDataPartition(training$classe, p = 0.75, list = FALSE)
validation <- training[-in_train,]
training <- training[in_train,]
corvars <- cor(training[, -53]) #create correlation matrix
diag(corvars) <- 0
indices <- which(abs(corvars) > 0.8, arr.ind = T) #determine names of highly correlated variables
corvars <- corvars[unique(rownames(indices)), unique(rownames(indices))] #subset matrix
diag(corvars) <- 1
corrplot(
corvars,
method = "square",
type = "upper",
order = "FPC",
tl.cex = 0.7
) #create a heatmap of highly correlated features
cluster <- makeCluster(detectCores() - 1); registerDoParallel(cluster) #initiate cluster for parallel processing
fitControl <- trainControl(method = "cv", number = 5, allowParallel = TRUE) #define parameters for cross validation
set.seed(2358)
fitlda <- train(classe~., method="lda", preProcess = "pca" , data=training, trControl = fitControl) #train lda with PCA dim reduction
fittree <- train(classe~., method="rpart", data=training, trControl = fitControl) #train tree classification
fitgbm <- train(classe~., method="gbm", data=training, trControl = fitControl) #train gbm classification
fitsvm <- svm(classe~., data=training, type = "C", cross = 5) #train svm classification
fitrftime <- system.time(fitrf <- train(classe~., method="rf", data=training, trControl = fitControl)) #train random forest classification
fitrftime
fitrf$finalModel
data.frame(model_type = c("lda", "tree","gbm","svm","rf"),
in_sample_accuracy = c(max(fitlda$results[2]),
max(fittree$results[2]),
max(fitgbm$results[5]),
fitsvm$tot.accuracy/100,
max(fitrf$results[2]))
) #compares in sample accuracies
fitrf$finalModel #shows OOB error
confusionMatrix(predict(fitrf, validation), validation$classe)$overall #shows OOSA and CI
vars <- varImp(fitrf)$importance #determine feature importance
vars <- vars%>%mutate(names=rownames(vars))%>%arrange(desc(Overall))%>%filter(Overall>10) #select top 20 or so features
newformula <- paste0("classe~", vars$names[1])
for (i in 2:length(vars$names)){newformula <- paste(newformula, vars$names[i], sep="+")} #define a new formula
fitrf2time <- system.time(fitrf2 <- train(as.formula(newformula), method="rf", data=training, trControl = fitControl)) #refit the rf model
fitrf2$finalModel #shows OOB error
confusionMatrix(predict(fitrf2, validation), validation$classe)$overall #shows OOSA and CI
cat("The system times for the fits were:")
data.frame(rbind(first_fit = fitrftime[3], second_fit = fitrf2time[3]))
data.frame(testing$problem_id, classe.prediction.fitrf = predict(fitrf, testing), classe.prediction.fitrf2 = predict(fitrf2, testing))
stopCluster(cluster); registerDoSEQ() #return to single thread
